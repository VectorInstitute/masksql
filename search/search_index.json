{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MaskSQL","text":""},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Run MaskSQL</li> <li>MaskSql Framework</li> <li>MaskSQL Pipeline Stages</li> </ul>"},{"location":"#installation-and-setup-instructions","title":"Installation and Setup Instructions","text":""},{"location":"#system-requirements","title":"System Requirements","text":"<p>The development environment (tested on python 3.11) can be set up using uv. Hence, make sure it is installed and then run:</p> <pre><code>uv sync --dev\nsource .venv/bin/activate\n</code></pre>"},{"location":"#download-dataset","title":"Download Dataset","text":"<p>Download this zip file and extract it to the <code>data</code> directory:</p> <pre><code>wget -O data.zip \"https://www.dropbox.com/scl/fi/vtraf79vfi1x105veaflk/data.zip?rlkey=7yq6d46aer6h45pdihrc9rht1&amp;st=zdac3rqx&amp;dl=0\"\nunzip data.zip\n</code></pre> <p>Your data directory should look like this:</p> <pre><code>data/\n\u251c\u2500\u2500 databases/\n\u251c\u2500\u2500 1_input.json\n.\n.\n.\n</code></pre>"},{"location":"#set-environment-variables","title":"Set Environment Variables","text":"<pre><code>cp .env.example .env\n</code></pre> <p>The only required variable to set is <code>OPENAI_API_KEY</code>. By default, we are using OpenRouter, so you need to set the api key for OpenRouter.</p> <p>You may also change the <code>LIMIT</code> variable to modify the number of entries to be read from the dataset. <code>START</code> specifies the start index for reading from the dataset.</p> <p>For instance, set <code>LIMIT=10</code> to run the pipeline for a dataset of size 10.</p> <p><code>SLM_MODEL</code> and <code>LLM_MODEL</code> specify the ID of small/large language models to be used in the pipeline. These IDs should be set based on the LM provider being used. For instance, since we are using OpenRouter, model identifiers should be specified accordingly, e.g., <code>openai/gpt-4.1</code> for GPT-4.1.</p>"},{"location":"#run-resdsql","title":"Run RESDSQL","text":"<p>To run MaskSQL, first we need to filter the schema items using RESDSQL. Follow these instructions to run the RESDSQL and generated the file needed for the MaskSQL pipeline. Then, you need to run the MaskSQL with the <code>--resd</code> option.</p>"},{"location":"#run-masksql","title":"Run MaskSQL","text":"<p>Then you can run MaskSQL pipline as follows: <pre><code>python3 main.py --resd\n</code></pre></p> <p>MaskSQL saves the intermediate results to files for later user. So, in order to run the pipeline from scratch you need to clean the data directory: <pre><code>./clean.sh data\n</code></pre></p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#top-level-module","title":"Top Level Module","text":""},{"location":"user_guide/","title":"User Guide","text":""}]}